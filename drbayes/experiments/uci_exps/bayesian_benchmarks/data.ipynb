{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from urllib.request import urlopen\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import zipfile\n",
    "\n",
    "#from bayesian_benchmarks.paths import DATA_PATH, BASE_SEED\n",
    "\n",
    "_ALL_REGRESSION_DATATSETS = {}\n",
    "_ALL_CLASSIFICATION_DATATSETS = {}\n",
    "\n",
    "def add_regression(C):\n",
    "    _ALL_REGRESSION_DATATSETS.update({C.name:C})\n",
    "    return C\n",
    "\n",
    "def add_classficiation(C):\n",
    "    _ALL_CLASSIFICATION_DATATSETS.update({C.name:C})\n",
    "    return C\n",
    "\n",
    "def normalize(X):\n",
    "    X_mean = np.average(X, 0)[None, :]\n",
    "    X_std = 1e-6 + np.std(X, 0)[None, :]\n",
    "    return (X - X_mean) / X_std, X_mean, X_std\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, split=0, prop=0.9):\n",
    "        if self.needs_download:\n",
    "            self.download()\n",
    "\n",
    "        X_raw, Y_raw = self.read_data()\n",
    "        X, Y = self.preprocess_data(X_raw, Y_raw)\n",
    "\n",
    "        ind = np.arange(self.N)\n",
    "\n",
    "        np.random.seed(BASE_SEED + split)\n",
    "        #np.random.shuffle(ind)\n",
    "\n",
    "        n = int(self.N * prop)\n",
    "        ###################\n",
    "        N = Y.shape[0]\n",
    "\n",
    "        # Get indices of test and training/validation data at random\n",
    "        indices = np.arange(N)\n",
    "        trainval_idx = indices[0:round(N*0.9)]\n",
    "        test_idx = indices[round(N*0.9):-1]\n",
    "        ###################\n",
    "\n",
    "        self.X_train = X[trainval_idx, :]\n",
    "        self.Y_train = Y[trainval_idx, :]\n",
    "\n",
    "        self.X_test = X[test_idx, :]\n",
    "        self.Y_test = Y[test_idx, :]\n",
    "\n",
    "    @property\n",
    "    def datadir(self):\n",
    "        dir = os.path.join(DATA_PATH, self.name)\n",
    "        if not os.path.isdir(dir):\n",
    "            os.mkdir(dir)\n",
    "        return dir\n",
    "\n",
    "    @property\n",
    "    def datapath(self):\n",
    "        filename = self.url.split('/')[-1]  # this is for the simple case with no zipped files\n",
    "        return os.path.join(self.datadir, filename)\n",
    "\n",
    "    @property\n",
    "    def needs_download(self):\n",
    "        return not os.path.isfile(self.datapath)\n",
    "\n",
    "    def download(self):\n",
    "        logging.info('donwloading {} data'.format(self.name))\n",
    "\n",
    "        is_zipped = np.any([z in self.url for z in ['.gz', '.zip', '.tar']])\n",
    "\n",
    "        if is_zipped:\n",
    "            filename = os.path.join(self.datadir, self.url.split('/')[-1])\n",
    "        else:\n",
    "            filename = self.datapath\n",
    "\n",
    "        with urlopen(self.url) as response, open(filename, 'wb') as out_file:\n",
    "            data = response.read()\n",
    "            out_file.write(data)\n",
    "\n",
    "        if is_zipped:\n",
    "            zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "            zip_ref.extractall(self.datadir)\n",
    "            zip_ref.close()\n",
    "\n",
    "            # os.remove(filename)\n",
    "\n",
    "        logging.info('finished donwloading {} data'.format(self.name))\n",
    "\n",
    "    def read_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def preprocess_data(self, X, Y):\n",
    "        X, self.X_mean, self.X_std = normalize(X)\n",
    "        Y, self.Y_mean, self.Y_std = normalize(Y)\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "uci_base_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Boston(Dataset):\n",
    "    N, D, name = 506, 13, 'boston'\n",
    "    url = uci_base_url + 'housing/housing.data'\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_fwf(self.datapath, header=None).values\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Concrete(Dataset):\n",
    "    N, D, name = 1030, 8, 'concrete'\n",
    "    url = uci_base_url + 'concrete/compressive/Concrete_Data.xls'\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_excel(self.datapath).values\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Energy(Dataset):\n",
    "    N, D, name = 768, 8, 'energy'\n",
    "    url = uci_base_url + '00242/ENB2012_data.xlsx'\n",
    "    def read_data(self):\n",
    "        # NB this is the first output (aka Energy1, as opposed to Energy2)\n",
    "        data = pandas.read_excel(self.datapath).values[:, :-1]\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Kin8mn(Dataset):\n",
    "    N, D, name = 8192, 8, 'kin8nm'\n",
    "    url = 'http://mldata.org/repository/data/download/csv/uci-20070111-kin8nm'\n",
    "    def read_data(self):\n",
    "        data = pandas.read_csv(self.datapath, header=None).values\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Naval(Dataset):\n",
    "    N, D, name = 11934, 14, 'naval'\n",
    "    url = uci_base_url + '00316/UCI%20CBM%20Dataset.zip'\n",
    "\n",
    "    @property\n",
    "    def datapath(self):\n",
    "        return os.path.join(self.datadir, 'UCI CBM Dataset/data.txt')\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_fwf(self.datapath, header=None).values\n",
    "        # NB this is the first output\n",
    "        X = data[:, :-2]\n",
    "        Y = data[:, -2].reshape(-1, 1)\n",
    "\n",
    "        # dims 8 and 11 have std=0:\n",
    "        X = np.delete(X, [8, 11], axis=1)\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Power(Dataset):\n",
    "    N, D, name = 9568, 4, 'power'\n",
    "    url = uci_base_url + '00294/CCPP.zip'\n",
    "\n",
    "    @property\n",
    "    def datapath(self):\n",
    "        return os.path.join(self.datadir, 'CCPP/Folds5x2_pp.xlsx')\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_excel(self.datapath).values\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Protein(Dataset):\n",
    "    N, D, name = 45730, 9, 'protein'\n",
    "    url = uci_base_url + '00265/CASP.csv'\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_csv(self.datapath).values\n",
    "        return data[:, 1:], data[:, 0].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class WineRed(Dataset):\n",
    "    N, D, name = 1599, 11, 'winered'\n",
    "    url = uci_base_url + 'wine-quality/winequality-red.csv'\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_csv(self.datapath, delimiter=';').values\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class WineWhite(Dataset):\n",
    "    N, D, name = 4898, 11, 'winewhite'\n",
    "    url = uci_base_url + 'wine-quality/winequality-white.csv'\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Yacht(Dataset):\n",
    "    N, D, name = 308, 6, 'yacht'\n",
    "    url = uci_base_url + '/00243/yacht_hydrodynamics.data'\n",
    "\n",
    "    def read_data(self):\n",
    "        data = pandas.read_fwf(self.datapath, header=None).values[:-1, :]\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "class Classification(Dataset):\n",
    "    def preprocess_data(self, X, Y):\n",
    "        X, self.X_mean, self.X_std = normalize(X)\n",
    "        return X, Y\n",
    "\n",
    "    @property\n",
    "    def needs_download(self):\n",
    "        if os.path.isfile(os.path.join(DATA_PATH, 'classification_data', 'iris', 'iris_R.dat')):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def download(self):\n",
    "        logging.info('donwloading classification data. WARNING: downloading 195MB file'.format(self.name))\n",
    "\n",
    "        filename = os.path.join(DATA_PATH, 'classification_data.tar.gz')\n",
    "\n",
    "        url = 'http://persoal.citius.usc.es/manuel.fernandez.delgado/papers/jmlr/data.tar.gz'\n",
    "        with urlopen(url) as response, open(filename, 'wb') as out_file:\n",
    "            data = response.read()\n",
    "            out_file.write(data)\n",
    "\n",
    "        import tarfile\n",
    "        tar = tarfile.open(filename)\n",
    "        tar.extractall(path=os.path.join(DATA_PATH, 'classification_data'))\n",
    "        tar.close()\n",
    "\n",
    "        logging.info('finished donwloading {} data'.format(self.name))\n",
    "\n",
    "\n",
    "    def read_data(self):\n",
    "        datapath = os.path.join(DATA_PATH, 'classification_data', self.name, self.name + '_R.dat')\n",
    "        if os.path.isfile(datapath):\n",
    "            data = np.array(pandas.read_csv(datapath, header=0, delimiter='\\t').values).astype(float)\n",
    "        else:\n",
    "            data_path1 = os.path.join(DATA_PATH, 'classification_data', self.name, self.name + '_train_R.dat')\n",
    "            data1 = np.array(pandas.read_csv(data_path1, header=0, delimiter='\\t').values).astype(float)\n",
    "\n",
    "            data_path2 = os.path.join(DATA_PATH, 'classification_data', self.name, self.name + '_test_R.dat')\n",
    "            data2 = np.array(pandas.read_csv(data_path2, header=0, delimiter='\\t').values).astype(float)\n",
    "\n",
    "            data = np.concatenate([data1, data2], 0)\n",
    "\n",
    "        return data[:, :-1], data[:, -1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "rescale = lambda x, a, b: b[0] + (b[1] - b[0]) * x / (a[1] - a[0])\n",
    "\n",
    "\n",
    "def convert_to_day_minute(d):\n",
    "    day_of_week = rescale(float(d.weekday()), [0, 6], [0, 2 * np.pi])\n",
    "    time_of_day = rescale(d.time().hour * 60 + d.time().minute, [0, 24 * 60], [0, 2 * np.pi])\n",
    "    return day_of_week, time_of_day\n",
    "\n",
    "\n",
    "def process_time(pickup_datetime, dropoff_datetime):\n",
    "    d_pickup = datetime.strptime(pickup_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    d_dropoff = datetime.strptime(dropoff_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    duration = (d_dropoff - d_pickup).total_seconds()\n",
    "\n",
    "    pickup_day_of_week, pickup_time_of_day = convert_to_day_minute(d_pickup)\n",
    "    dropoff_day_of_week, dropoff_time_of_day = convert_to_day_minute(d_dropoff)\n",
    "\n",
    "    return [pickup_day_of_week, pickup_time_of_day,\n",
    "            dropoff_day_of_week, dropoff_time_of_day,\n",
    "            duration]\n",
    "\n",
    "\n",
    "class NYTaxiBase(Dataset):\n",
    "    x_bounds = [-74.04, -73.75]\n",
    "    y_bounds = [40.62, 40.86]\n",
    "    too_close_radius = 0.00001\n",
    "    min_duration = 30\n",
    "    max_duration = 3 * 3600\n",
    "    name = 'nytaxi'\n",
    "\n",
    "    def _read_data(self):\n",
    "        data = pandas.read_csv(self.datapath)#, nrows=10000)\n",
    "        data = data.values\n",
    "\n",
    "        # print(data.dtypes.index)\n",
    "        # 'id',  0\n",
    "        # 'vendor_id',  1\n",
    "        # 'pickup_datetime', 2\n",
    "        # 'dropoff_datetime',3\n",
    "        # 'passenger_count', 4\n",
    "        # 'pickup_longitude', 5\n",
    "        # 'pickup_latitude',6\n",
    "        # 'dropoff_longitude', 7\n",
    "        # 'dropoff_latitude', 8\n",
    "        # 'store_and_fwd_flag',9\n",
    "        # 'trip_duration'10\n",
    "\n",
    "        pickup_loc = np.array((data[:, 5], data[:, 6])).T\n",
    "        dropoff_loc = np.array((data[:, 7], data[:, 8])).T\n",
    "\n",
    "        ind = np.ones(len(data)).astype(bool)\n",
    "        ind[data[:, 5] < self.x_bounds[0]] = False\n",
    "        ind[data[:, 5] > self.x_bounds[1]] = False\n",
    "        ind[data[:, 6] < self.y_bounds[0]] = False\n",
    "        ind[data[:, 6] > self.y_bounds[1]] = False\n",
    "\n",
    "        ind[data[:, 7] < self.x_bounds[0]] = False\n",
    "        ind[data[:, 7] > self.x_bounds[1]] = False\n",
    "        ind[data[:, 8] < self.y_bounds[0]] = False\n",
    "        ind[data[:, 8] > self.y_bounds[1]] = False\n",
    "\n",
    "        print('discarding {} out of bounds {} {}'.format(np.sum(np.invert(ind).astype(int)), self.x_bounds,\n",
    "                                                         self.y_bounds))\n",
    "\n",
    "        early_stop = ((data[:, 5] - data[:, 7]) ** 2 + (data[:, 6] - data[:, 8]) ** 2 < self.too_close_radius)\n",
    "        ind[early_stop] = False\n",
    "        print('discarding {} trip less than {} gp dist'.format(np.sum(early_stop.astype(int)),\n",
    "                                                               self.too_close_radius ** 0.5))\n",
    "\n",
    "        times = np.array([process_time(d_pickup, d_dropoff) for (d_pickup, d_dropoff) in data[:, 2:4]])\n",
    "        pickup_time = times[:, :2]\n",
    "        dropoff_time = times[:, 2:4]\n",
    "        duration = times[:, 4]\n",
    "\n",
    "        short_journeys = (duration < self.min_duration)\n",
    "        ind[short_journeys] = False\n",
    "        print('discarding {} less than {}s journeys'.format(np.sum(short_journeys.astype(int)), self.min_duration))\n",
    "\n",
    "        long_journeys = (duration > self.max_duration)\n",
    "        ind[long_journeys] = False\n",
    "        print(\n",
    "            'discarding {} more than {}h journeys'.format(np.sum(long_journeys.astype(int)), self.max_duration / 3600.))\n",
    "\n",
    "        pickup_loc = pickup_loc[ind, :]\n",
    "        dropoff_loc = dropoff_loc[ind, :]\n",
    "        pickup_time = pickup_time[ind, :]\n",
    "        dropoff_time = dropoff_time[ind, :]\n",
    "        duration = duration[ind]\n",
    "\n",
    "        print('{} total rejected journeys'.format(np.sum(np.invert(ind).astype(int))))\n",
    "        return pickup_loc, dropoff_loc, pickup_time, dropoff_time, duration\n",
    "\n",
    "    @property\n",
    "    def datapath(self):\n",
    "        filename = 'train.csv'\n",
    "        return os.path.join(self.datadir, filename)\n",
    "\n",
    "    def download(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class NYTaxiTimePrediction(NYTaxiBase):\n",
    "    N, D = 1420068, 8\n",
    "    # N, D = 9741, 6\n",
    "\n",
    "    def read_data(self):\n",
    "        path = os.path.join(DATA_PATH, 'taxitime_preprocessed.npz')\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'rb') as file:\n",
    "                f = np.load(file)\n",
    "                X, Y = f['X'], f['Y']\n",
    "\n",
    "        else:\n",
    "            pickup_loc, dropoff_loc, pickup_datetime, dropoff_datetime, duration = self._read_data()\n",
    "\n",
    "            pickup_sc = np.array([np.sin(pickup_datetime[:, 0]),\n",
    "                                  np.cos(pickup_datetime[:, 0]),\n",
    "                                  np.sin(pickup_datetime[:, 1]),\n",
    "                                  np.cos(pickup_datetime[:, 1])]).T\n",
    "\n",
    "            X = np.concatenate([pickup_loc, dropoff_loc, pickup_sc], 1)\n",
    "            Y = duration.reshape(-1, 1)\n",
    "            X, Y = np.array(X).astype(float), np.array(Y).astype(float)\n",
    "            with open(path, 'wb') as file:\n",
    "                np.savez(file, X=X, Y=Y)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "class NYTaxiLocationPrediction(NYTaxiBase):\n",
    "    N, D = 1420068, 6\n",
    "    def read_data(self):\n",
    "        path = os.path.join(DATA_PATH, 'taxiloc_preprocessed.npz')\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'rb') as file:\n",
    "                f = np.load(file)\n",
    "                X, Y = f['X'], f['Y']\n",
    "\n",
    "        else:\n",
    "\n",
    "            pickup_loc, dropoff_loc, pickup_datetime, dropoff_datetime, duration = self._read_data()\n",
    "\n",
    "            pickup_sc = np.array([np.sin(pickup_datetime[:, 0]),\n",
    "                                  np.cos(pickup_datetime[:, 0]),\n",
    "                                  np.sin(pickup_datetime[:, 1]),\n",
    "                                  np.cos(pickup_datetime[:, 1])]).T\n",
    "            #         X = np.concatenate([pickup_loc, pickup_sc, duration.reshape(-1, 1)], 1)\n",
    "            X = np.concatenate([pickup_loc, pickup_sc], 1)\n",
    "            Y = dropoff_loc\n",
    "            X, Y = np.array(X).astype(float), np.array(Y).astype(float)\n",
    "\n",
    "            with open(path, 'wb') as file:\n",
    "                np.savez(file, X=X, Y=Y)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def preprocess_data(self, X, Y):\n",
    "        return X, Y\n",
    "\n",
    "# Andrew Wilson's datasets\n",
    "#https://drive.google.com/open?id=0BxWe_IuTnMFcYXhxdUNwRHBKTlU\n",
    "class WilsonDataset(Dataset):\n",
    "    @property\n",
    "    def datapath(self):\n",
    "        n = self.name[len('wilson_'):]\n",
    "        return '{}/uci/{}/{}.mat'.format(DATA_PATH, n, n)\n",
    "\n",
    "    def read_data(self):\n",
    "        data = loadmat(self.datapath)['data']\n",
    "        return data[:, :-1], data[:, -1, None]\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_3droad(WilsonDataset):\n",
    "    name, N, D =  'wilson_3droad', 434874, 3\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_challenger(WilsonDataset):\n",
    "    name, N, D = 'wilson_challenger', 23, 4\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_gas(WilsonDataset):\n",
    "    name, N, D = 'wilson_gas', 2565, 128\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_servo(WilsonDataset):\n",
    "    name, N, D = 'wilson_servo', 167, 4\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_tamielectric(WilsonDataset):\n",
    "    name, N, D = 'wilson_tamielectric', 45781, 3\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_airfoil(WilsonDataset):\n",
    "    name, N, D = 'wilson_airfoil', 1503, 5\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_concrete(WilsonDataset):\n",
    "    name, N, D = 'wilson_concrete', 1030, 8\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_machine(WilsonDataset):\n",
    "    name, N, D = 'wilson_machine', 209, 7\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_skillcraft(WilsonDataset):\n",
    "    name, N, D =  'wilson_skillcraft', 3338, 19\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_wine(WilsonDataset):\n",
    "    name, N, D =  'wilson_wine', 1599, 11\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_autompg(WilsonDataset):\n",
    "    name, N, D =  'wilson_autompg', 392, 7\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_concreteslump(WilsonDataset):\n",
    "    name, N, D = 'wilson_concreteslump', 103, 7\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_houseelectric(WilsonDataset):\n",
    "    name, N, D = 'wilson_houseelectric', 2049280, 11\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_parkinsons(WilsonDataset):\n",
    "    name, N, D = 'wilson_parkinsons', 5875, 20\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_slice(WilsonDataset):\n",
    "    name, N, D = 'wilson_slice', 53500, 385\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_yacht(WilsonDataset):\n",
    "    name, N, D = 'wilson_yacht', 308, 6\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_autos(WilsonDataset):\n",
    "    name, N, D = 'wilson_autos', 159, 25\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_elevators(WilsonDataset):\n",
    "    name, N, D = 'wilson_elevators', 16599, 18\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_housing(WilsonDataset):\n",
    "    name, N, D = 'wilson_housing', 506, 13\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_pendulum(WilsonDataset):\n",
    "    name, N, D =  'wilson_pendulum', 630, 9\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_sml(WilsonDataset):\n",
    "    name, N, D =  'wilson_sml', 4137, 26\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_bike(WilsonDataset):\n",
    "    name, N, D = 'wilson_bike', 17379, 17\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_energy(WilsonDataset):\n",
    "    name, N, D = 'wilson_energy', 768, 8\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_keggdirected(WilsonDataset):\n",
    "    name, N, D = 'wilson_keggdirected', 48827, 20\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_pol(WilsonDataset):\n",
    "    name, N, D = 'wilson_pol', 15000, 26\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_solar(WilsonDataset):\n",
    "    name, N, D = 'wilson_solar', 1066, 10\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_breastcancer(WilsonDataset):\n",
    "    name, N, D = 'wilson_breastcancer', 194, 33\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_fertility(WilsonDataset):\n",
    "    name, N, D = 'wilson_fertility', 100, 9\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_keggundirected(WilsonDataset):\n",
    "    name, N, D = 'wilson_keggundirected', 63608, 27\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_protein(WilsonDataset):\n",
    "    name, N, D = 'wilson_protein', 45730, 9\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_song(WilsonDataset):\n",
    "    name, N, D = 'wilson_song', 515345, 90\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_buzz(WilsonDataset):\n",
    "    name, N, D = 'wilson_buzz', 583250, 77\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_forest(WilsonDataset):\n",
    "    name, N, D = 'wilson_forest', 517, 12\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_kin40k(WilsonDataset):\n",
    "    name, N, D = 'wilson_kin40k', 40000, 8\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_pumadyn32nm(WilsonDataset):\n",
    "    name, N, D = 'wilson_pumadyn32nm', 8192, 32\n",
    "\n",
    "\n",
    "@add_regression\n",
    "class Wilson_stock(WilsonDataset):\n",
    "    name, N, D = 'wilson_stock', 536, 11\n",
    "\n",
    "\n",
    "classification_datasets = [\n",
    "    ['heart-va', 200, 13, 5],\n",
    "    ['connect-4', 67557, 43, 2],\n",
    "    ['wine', 178, 14, 3],\n",
    "    ['tic-tac-toe', 958, 10, 2],\n",
    "    ['fertility', 100, 10, 2],\n",
    "    ['statlog-german-credit', 1000, 25, 2],\n",
    "    ['car', 1728, 7, 4],\n",
    "    ['libras', 360, 91, 15],\n",
    "    ['spambase', 4601, 58, 2],\n",
    "    ['pittsburg-bridges-MATERIAL', 106, 8, 3],\n",
    "    ['hepatitis', 155, 20, 2],\n",
    "    ['acute-inflammation', 120, 7, 2],\n",
    "    ['pittsburg-bridges-TYPE', 105, 8, 6],\n",
    "    ['arrhythmia', 452, 263, 13],\n",
    "    ['musk-2', 6598, 167, 2],\n",
    "    ['twonorm', 7400, 21, 2],\n",
    "    ['nursery', 12960, 9, 5],\n",
    "    ['breast-cancer-wisc-prog', 198, 34, 2],\n",
    "    ['seeds', 210, 8, 3],\n",
    "    ['lung-cancer', 32, 57, 3],\n",
    "    ['waveform', 5000, 22, 3],\n",
    "    ['audiology-std', 196, 60, 18],\n",
    "    ['trains', 10, 30, 2],\n",
    "    ['horse-colic', 368, 26, 2],\n",
    "    ['miniboone', 130064, 51, 2],\n",
    "    ['pittsburg-bridges-SPAN', 92, 8, 3],\n",
    "    ['breast-cancer-wisc-diag', 569, 31, 2],\n",
    "    ['statlog-heart', 270, 14, 2],\n",
    "    ['blood', 748, 5, 2],\n",
    "    ['primary-tumor', 330, 18, 15],\n",
    "    ['cylinder-bands', 512, 36, 2],\n",
    "    ['glass', 214, 10, 6],\n",
    "    ['contrac', 1473, 10, 3],\n",
    "    ['statlog-shuttle', 58000, 10, 7],\n",
    "    ['zoo', 101, 17, 7],\n",
    "    ['musk-1', 476, 167, 2],\n",
    "    ['hill-valley', 1212, 101, 2],\n",
    "    ['hayes-roth', 160, 4, 3],\n",
    "    ['optical', 5620, 63, 10],\n",
    "    ['credit-approval', 690, 16, 2],\n",
    "    ['pendigits', 10992, 17, 10],\n",
    "    ['pittsburg-bridges-REL-L', 103, 8, 3],\n",
    "    ['dermatology', 366, 35, 6],\n",
    "    ['soybean', 683, 36, 18],\n",
    "    ['ionosphere', 351, 34, 2],\n",
    "    ['planning', 182, 13, 2],\n",
    "    ['energy-y1', 768, 9, 3],\n",
    "    ['acute-nephritis', 120, 7, 2],\n",
    "    ['pittsburg-bridges-T-OR-D', 102, 8, 2],\n",
    "    ['letter', 20000, 17, 26],\n",
    "    ['titanic', 2201, 4, 2],\n",
    "    ['adult', 48842, 15, 2],\n",
    "    ['lymphography', 148, 19, 4],\n",
    "    ['statlog-australian-credit', 690, 15, 2],\n",
    "    ['chess-krvk', 28056, 7, 18],\n",
    "    ['bank', 4521, 17, 2],\n",
    "    ['statlog-landsat', 6435, 37, 6],\n",
    "    ['heart-hungarian', 294, 13, 2],\n",
    "    ['flags', 194, 29, 8],\n",
    "    ['mushroom', 8124, 22, 2],\n",
    "    ['conn-bench-sonar-mines-rocks', 208, 61, 2],\n",
    "    ['image-segmentation', 2310, 19, 7],\n",
    "    ['congressional-voting', 435, 17, 2],\n",
    "    ['annealing', 898, 32, 5],\n",
    "    ['semeion', 1593, 257, 10],\n",
    "    ['echocardiogram', 131, 11, 2],\n",
    "    ['statlog-image', 2310, 19, 7],\n",
    "    ['wine-quality-white', 4898, 12, 7],\n",
    "    ['lenses', 24, 5, 3],\n",
    "    ['plant-margin', 1600, 65, 100],\n",
    "    ['post-operative', 90, 9, 3],\n",
    "    ['thyroid', 7200, 22, 3],\n",
    "    ['monks-2', 601, 7, 2],\n",
    "    ['molec-biol-promoter', 106, 58, 2],\n",
    "    ['chess-krvkp', 3196, 37, 2],\n",
    "    ['balloons', 16, 5, 2],\n",
    "    ['low-res-spect', 531, 101, 9],\n",
    "    ['plant-texture', 1599, 65, 100],\n",
    "    ['haberman-survival', 306, 4, 2],\n",
    "    ['spect', 265, 23, 2],\n",
    "    ['plant-shape', 1600, 65, 100],\n",
    "    ['parkinsons', 195, 23, 2],\n",
    "    ['oocytes_merluccius_nucleus_4d', 1022, 42, 2],\n",
    "    ['conn-bench-vowel-deterding', 990, 12, 11],\n",
    "    ['ilpd-indian-liver', 583, 10, 2],\n",
    "    ['heart-cleveland', 303, 14, 5],\n",
    "    ['synthetic-control', 600, 61, 6],\n",
    "    ['vertebral-column-2clases', 310, 7, 2],\n",
    "    ['teaching', 151, 6, 3],\n",
    "    ['cardiotocography-10clases', 2126, 22, 10],\n",
    "    ['heart-switzerland', 123, 13, 5],\n",
    "    ['led-display', 1000, 8, 10],\n",
    "    ['molec-biol-splice', 3190, 61, 3],\n",
    "    ['wall-following', 5456, 25, 4],\n",
    "    ['statlog-vehicle', 846, 19, 4],\n",
    "    ['ringnorm', 7400, 21, 2],\n",
    "    ['energy-y2', 768, 9, 3],\n",
    "    ['oocytes_trisopterus_nucleus_2f', 912, 26, 2],\n",
    "    ['yeast', 1484, 9, 10],\n",
    "    ['oocytes_merluccius_states_2f', 1022, 26, 3],\n",
    "    ['oocytes_trisopterus_states_5b', 912, 33, 3],\n",
    "    ['breast-cancer-wisc', 699, 10, 2],\n",
    "    ['steel-plates', 1941, 28, 7],\n",
    "    ['mammographic', 961, 6, 2],\n",
    "    ['monks-3', 554, 7, 2],\n",
    "    ['balance-scale', 625, 5, 3],\n",
    "    ['ecoli', 336, 8, 8],\n",
    "    ['spectf', 267, 45, 2],\n",
    "    ['monks-1', 556, 7, 2],\n",
    "    ['page-blocks', 5473, 11, 5],\n",
    "    ['magic', 19020, 11, 2],\n",
    "    ['pima', 768, 9, 2],\n",
    "    ['breast-tissue', 106, 10, 6],\n",
    "    ['ozone', 2536, 73, 2],\n",
    "    ['iris', 150, 5, 3],\n",
    "    ['waveform-noise', 5000, 41, 3],\n",
    "    ['cardiotocography-3clases', 2126, 22, 3],\n",
    "    ['wine-quality-red', 1599, 12, 6],\n",
    "    ['vertebral-column-3clases', 310, 7, 3],\n",
    "    ['breast-cancer', 286, 10, 2],\n",
    "    ['abalone', 4177, 9, 3],\n",
    "]\n",
    "\n",
    "\n",
    "for name, N, D, K in classification_datasets:\n",
    "    @add_classficiation\n",
    "    class C(Classification):\n",
    "        name, N, D, K = name, N, D, K\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "regression_datasets = list(_ALL_REGRESSION_DATATSETS.keys())\n",
    "regression_datasets.sort()\n",
    "\n",
    "classification_datasets = list(_ALL_CLASSIFICATION_DATATSETS.keys())\n",
    "classification_datasets.sort()\n",
    "\n",
    "def get_regression_data(name, *args, **kwargs):\n",
    "    return _ALL_REGRESSION_DATATSETS[name](*args, **kwargs)\n",
    "\n",
    "def get_classification_data(name, *args, **kwargs):\n",
    "    return _ALL_CLASSIFICATION_DATATSETS[name](*args, **kwargs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
